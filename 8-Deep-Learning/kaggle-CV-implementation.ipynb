{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "# modified to work with the kaggle dogs and cats database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1- Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kaggle dataset operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate and convert datasets to an array.\n",
    "\n",
    "DATADIR = \"kagglecatsanddogs_5340/PetImages\"\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category) # path to dataset directory\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "        plt.imshow(img_array, cmap='gray')\n",
    "        plt.show()\n",
    "        break\n",
    "    break\n",
    "\n",
    "# Checking Data\n",
    "print('Data Array:\\n',img_array,'\\n')\n",
    "print('Data Shape:',img_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 80\n",
    "new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "plt.imshow(new_array, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create dataset for training\n",
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category) # categories for dog(0) and cat(1)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "                training_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        \n",
    "create_training_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_data))\n",
    "print(training_data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshuffle Data\n",
    "random.shuffle(training_data)\n",
    "\n",
    "# Check the shuffled data\n",
    "for sample in training_data [:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "X = tf.expand_dims(X, axis=-1)\n",
    "X = tf.cast(X, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\n",
    "cnn.add((tf.keras.layers.MaxPool2D(pool_size=2, strides=2)))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\n",
    "cnn.add((tf.keras.layers.MaxPool2D(pool_size=2, strides=2)))\n",
    "cnn.add(tf.keras.layers.Flatten(input_shape=(IMG_SIZE, IMG_SIZE)))\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation=\"relu\", input_shape = (None, 100)))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(X, y, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
